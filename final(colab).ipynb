{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fl5EovisWip0"
   },
   "source": [
    "#  <font color='red'>Set up Colab Environment</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mOUNpPrvB7Hl"
   },
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j9kCRAEtB7RK"
   },
   "outputs": [],
   "source": [
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "a6EefvhqCBGY",
    "outputId": "efe7bfa0-a739-4a5f-aa53-0f9ce19a8420"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XH9hMYzaCBJR",
    "outputId": "712b9376-7ce5-4625-ab89-75f33fe0372f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are currently in the folder of  /content/gdrive/My Drive/Mercari2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/content/gdrive/My Drive/Mercari2')\n",
    "print(\"We are currently in the folder of \",os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EQ67yg4NDaFO"
   },
   "source": [
    "#  <font color='red'>Function 1</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "_oNMvrRlWip2",
    "outputId": "caf08f14-73b0-41e1-bcc8-ffa42dd76a66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis function takes \\'df_test\\' as input and gives out the predicted price \\'y\\' value(float).\\n\\n\\'df_test\\' is a data point takes the Inputs of \\n[\"train_id\" (index),\\n\"name\" (str),\\n\"item_condition_id\" (categorical),\\n\"category_name\" (str),\\n\"brand_name\" (str),\\n\"shipping\" (categorical),\\n\"item_description\" (str)]\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This function takes 'df_test' as input and gives out the predicted price 'y' value(float).\n",
    "\n",
    "'df_test' is a data point takes the Inputs of \n",
    "[\"train_id\" (index),\n",
    "\"name\" (str),\n",
    "\"item_condition_id\" (categorical),\n",
    "\"category_name\" (str),\n",
    "\"brand_name\" (str),\n",
    "\"shipping\" (categorical),\n",
    "\"item_description\" (str)]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DyxLoAePWip6"
   },
   "outputs": [],
   "source": [
    "# ref - https://www.kaggle.com/lopuhin/mercari-golf-0-3875-cv-in-75-loc-1900-s\n",
    "\n",
    "def data_preprocess(df):\n",
    "    df['name'] = df['name'].fillna('') + ' ' + df['brand_name'].fillna('')\n",
    "    df['text'] = (df['item_description'].fillna('') + ' ' + df['name'] + ' ' + df['category_name'].fillna(''))\n",
    "    return df[['name', 'text', 'shipping', 'item_condition_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QlXTVoE6Wip9"
   },
   "outputs": [],
   "source": [
    "def text_encoder(train,test,vect_type,params):\n",
    "    vectorizer = CountVectorizer(ngram_range = params[0],min_df = params[1],max_df = params[2],max_features = params[3],token_pattern = '\\w+',\n",
    "                                 dtype = np.float32) if vect_type == 'BOW' else TfidfVectorizer(ngram_range = params[0],min_df = params[1],\n",
    "                                                                                                max_df = params[2],max_features = params[3],token_pattern = '\\w+',\n",
    "                                                                                                dtype = np.float32)\n",
    "    train_transform = vectorizer.fit_transform(train)\n",
    "    test_transform = vectorizer.transform(test)\n",
    "    feat_names = vectorizer.get_feature_names()\n",
    "    return train_transform,test_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aq1ns8-wWip_"
   },
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "# https://gist.github.com/sebleier/554280\n",
    "# we are removing the words from the stop words list: 'no', 'nor', 'not'\n",
    "stopwords= ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "\n",
    "def text_preprocess(data):\n",
    "    preprocessed = []\n",
    "    # tqdm is for printing the status bar\n",
    "    for sentance in tqdm_notebook(data):\n",
    "        sent = decontracted(sentance)\n",
    "        sent = sent.replace('\\\\r', ' ')\n",
    "        sent = sent.replace('\\\\\"', ' ')\n",
    "        sent = sent.replace('\\\\n', ' ')\n",
    "        sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "        # https://gist.github.com/sebleier/554280\n",
    "        sent = ' '.join(e for e in sent.split() if e not in stopwords)\n",
    "        preprocessed.append(sent.lower().strip())\n",
    "    return preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jjhd17ApWiqC"
   },
   "outputs": [],
   "source": [
    "def dummy_encoder(train,test):\n",
    "    enc1 = CountVectorizer(vocabulary= list(train['shipping'].unique()), lowercase=False, binary=True)\n",
    "    train_transform1 = enc1.fit_transform(train['shipping'].astype(str))\n",
    "    test_transform1 = enc1.transform(test['shipping'].astype(str))\n",
    "\n",
    "    enc2 = CountVectorizer(vocabulary= list(train['item_condition_id'].unique()), lowercase=False, binary=True)\n",
    "    train_transform2 = enc2.fit_transform(train['item_condition_id'].astype(str))\n",
    "    test_transform2 = enc2.transform(test['item_condition_id'].astype(str))   \n",
    "\n",
    "    train_transform = scipy.sparse.hstack((train_transform1,train_transform2)).tocsr()\n",
    "    test_transform = scipy.sparse.hstack((test_transform1,test_transform2)).tocsr()\n",
    "    \n",
    "    return train_transform,test_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nsjY59kPWiqF"
   },
   "outputs": [],
   "source": [
    "def category_encoder(train,test):\n",
    "    unique_categories = pd.Series(\"/\".join(train[\"category_name\"].unique().astype(\"str\")).split(\"/\")).unique()\n",
    "    count_category = CountVectorizer(vocabulary = unique_categories,lowercase = False,binary = True)\n",
    "    train_transform = count_category.fit_transform(train[\"category_name\"])\n",
    "    test_transform = count_category.transform(test['category_name'])\n",
    "    return train_transform,test_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qMc5qf5nWiqI"
   },
   "outputs": [],
   "source": [
    "def brand_encoder(train,test):\n",
    "    vect = LabelBinarizer(sparse_output=True)\n",
    "    train_transform = vect.fit_transform(train[\"brand_name\"])\n",
    "    test_transform = vect.transform(test[\"brand_name\"])\n",
    "    return train_transform,test_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yVWMEpcmWiqL"
   },
   "outputs": [],
   "source": [
    "def ridge_model(X_train,y_train,params):\n",
    "    model = Ridge(solver = \"lsqr\", fit_intercept=False,alpha = params)\n",
    "    model.fit(X_train,y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "snGswu4LWiqN"
   },
   "outputs": [],
   "source": [
    "def build_mlp_model1(train_shape):\n",
    "    model_in = Input(shape=(train_shape,), dtype='float32',sparse = True)\n",
    "    out = Dense(256, activation='relu')(model_in)\n",
    "    out = Dense(64, activation='relu')(out)\n",
    "    out = Dense(64, activation='relu')(out)\n",
    "    out = Dense(32, activation='relu')(out)\n",
    "    model_out = Dense(1)(out)\n",
    "    model = Model(model_in, model_out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2IThtptbWiqP"
   },
   "outputs": [],
   "source": [
    "def build_mlp_model2(train_shape):\n",
    "    model_in = Input(shape=(train_shape,), dtype='float32',sparse = True)\n",
    "    out = Dense(1024, activation='relu')(model_in)\n",
    "    out = Dense(512, activation='relu')(out)\n",
    "    out = Dense(256, activation='relu')(out)\n",
    "    out = Dense(128, activation='relu')(out)\n",
    "    out = Dense(64, activation='relu')(out)\n",
    "    out = Dense(32, activation='relu')(out)\n",
    "    out = Dense(1)(out)\n",
    "    model = Model(model_in, out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-8lMRAJBWiqR"
   },
   "outputs": [],
   "source": [
    "def data_clean(df):\n",
    "    df = df[(df.price >= 3) & (df.price <= 2000)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ljYaUU06WiqU"
   },
   "outputs": [],
   "source": [
    "def function1(X_input):\n",
    "    \n",
    "    # (1) Load Data Files from Local...\n",
    "    df_train = pd.read_csv('train.tsv',sep = '\\t')\n",
    "    df_test = X_input\n",
    "    print(df_train.shape,df_test.shape)\n",
    "    print(\"(1) done\")\n",
    "    ##################################################################################\n",
    "    \n",
    "    # (2) Clean Data..\n",
    "    df_train = data_clean(df_train)\n",
    "    print(\"(2) done\")\n",
    "    ##################################################################################\n",
    "    \n",
    "    # (3) Encode Data..\n",
    "    y_scaler = StandardScaler()\n",
    "    y_train = y_scaler.fit_transform(np.log1p(df_train['price'].values.reshape(-1, 1)))\n",
    "    df_train = data_preprocess(df_train)\n",
    "    df_test = data_preprocess(df_test)\n",
    "    train_name,test_name = text_encoder(df_train['name'],df_test['name'],'TFIDF',((1,1),1,1.0,100000))\n",
    "    train_text,test_text = text_encoder(df_train['text'],df_test['text'],'TFIDF',((1,2),1,1.0,100000))\n",
    "    train_dummies,test_dummies = dummy_encoder(df_train,df_test)\n",
    "    X_train = scipy.sparse.hstack((train_name, train_text, train_dummies)).tocsr().astype('float32')\n",
    "    X_test = scipy.sparse.hstack((test_name, test_text, test_dummies)).tocsr().astype('float32')\n",
    "    ##################################################################################\n",
    "    \n",
    "    # (4) Train Models..\n",
    "    ridge = ridge_model(X_train,y_train,10)\n",
    "    preds = ridge.predict(X_test)[:, 0]\n",
    "    preds_ridge = np.expm1(y_scaler.inverse_transform(preds.reshape(-1, 1))[:, 0])\n",
    "\n",
    "    mlp1 = build_mlp_model1(X_train.shape[1])\n",
    "    mlp1.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    for i in range(2):\n",
    "        mlp1.fit(X_train,y_train,batch_size = 2**(8+i),epochs = 1,verbose = 1)\n",
    "    preds = mlp1.predict(X_test,verbose = 1)[:, 0]\n",
    "    preds_mlp1 = np.expm1(y_scaler.inverse_transform(preds.reshape(-1, 1))[:, 0])\n",
    "    \n",
    "    mlp2 = build_mlp_model2(X_train.shape[1])\n",
    "    mlp2.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    for i in range(2):\n",
    "        mlp2.fit(X_train,y_train,batch_size = 2**(8+i),epochs = 1,verbose = 1)\n",
    "    preds = mlp2.predict(X_test,verbose = 1)[:, 0]\n",
    "    preds_mlp2 = np.expm1(y_scaler.inverse_transform(preds.reshape(-1, 1))[:, 0])\n",
    "    ###################################################################################################################\n",
    "    \n",
    "    # (4) Generate Best Ensemble\n",
    "    preds_mlps = 0.55*preds_mlp1 + 0.45*preds_mlp2\n",
    "    preds_f = 0.1*preds_ridge + 0.9*preds_mlps\n",
    "    ###################################################################################################################\n",
    "    \n",
    "    # (6) Prediction\n",
    "    df_test['prediction'] = preds_f\n",
    "    return preds_f\n",
    "    ###################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "FYmEhg1KgR-z",
    "outputId": "fdcd512f-26b8-4237-fb92-9bd6504cc70a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ERROR! Session/line number was not unique in database. History logging moved to new session 63\n",
      "(1482535, 8) (1, 7)\n",
      "(1) done\n",
      "(2) done\n",
      "5788/5788 [==============================] - 105s 18ms/step - loss: 0.3627\n",
      "2894/2894 [==============================] - 58s 20ms/step - loss: 0.2202\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "5788/5788 [==============================] - 356s 62ms/step - loss: 0.3609\n",
      "2894/2894 [==============================] - 195s 67ms/step - loss: 0.2007\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "Predicted Price for  [[2 'Coach bag Coach' 1 'Vintage & Collectibles/Bags and Purses/Handbag'\n",
      "  'Coach' 1 'Brand new coach bag. Bought for [rm] at a Coach outlet.'\n",
      "  'Brand new coach bag. Bought for [rm] at a Coach outlet. Coach bag Coach Vintage & Collectibles/Bags and Purses/Handbag']]  is  [49.917088]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.sparse\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "from contextlib import contextmanager\n",
    "import os\n",
    "import re\n",
    "import gc\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer,StandardScaler,OneHotEncoder\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # Reading Test File as Input\n",
    "    gc.collect()\n",
    "    df_test = pd.read_csv('test.tsv',sep = '\\t')\n",
    "    df_input = df_test[2:3]\n",
    "    \n",
    "    # Sending input to function1\n",
    "    pred = function1(df_input)\n",
    "    print('Predicted Price for ',df_input.values,\" is \",pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "npVdIp3_WiqZ"
   },
   "source": [
    "#  <font color='red'>Function 2</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xhI-A6jpbBX-"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This function takes 'df_test' and the 'actual price' as input and returns the RMSLE score\n",
    "\n",
    "'df_test' is a data point takes the Inputs of \n",
    "[\"train_id\" (index),\n",
    "\"name\" (str),\n",
    "\"item_condition_id\" (categorical),\n",
    "\"category_name\" (str),\n",
    "\"brand_name\" (str),\n",
    "\"shipping\" (categorical),\n",
    "\"item_description\" (str)]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "barfx9rMaezP"
   },
   "outputs": [],
   "source": [
    "def rmsle_score(y, y_pred):\n",
    "    assert len(y) == len(y_pred)\n",
    "    to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n",
    "    return (sum(to_sum) * (1.0/len(y))) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vRb3CpvIafLj"
   },
   "outputs": [],
   "source": [
    "def function2(X,Y):\n",
    "    score = rmsle_score(function1(X),Y)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "id": "JoIYRxuUWiqd",
    "outputId": "ff5f46f0-e871-4721-f2ff-6c0b52ee5673"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1482535, 8) (1, 7)\n",
      "(1) done\n",
      "(2) done\n",
      "5788/5788 [==============================] - 107s 18ms/step - loss: 0.3624\n",
      "2894/2894 [==============================] - 59s 20ms/step - loss: 0.2201\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "5788/5788 [==============================] - 358s 62ms/step - loss: 0.3611\n",
      "2894/2894 [==============================] - 195s 67ms/step - loss: 0.2005\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "RMSLE score is  0.3231334323167663\n",
      "CPU times: user 11min 13s, sys: 4min 22s, total: 15min 36s\n",
      "Wall time: 15min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.sparse\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "from contextlib import contextmanager\n",
    "import os\n",
    "import re\n",
    "import gc\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer,StandardScaler,OneHotEncoder\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "      # Reading Test File as Input\n",
    "      gc.collect()\n",
    "      df_test = pd.read_csv('test.tsv',sep = '\\t')\n",
    "      df_input = df_test[2:3]\n",
    "      actual_price = [30]\n",
    "    \n",
    "      score = function2(df_input,actual_price)\n",
    "      print('RMSLE score is ',score)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "final(colab).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
